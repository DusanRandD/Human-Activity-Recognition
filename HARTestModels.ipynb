{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "import numpy as np\n",
    "X_train=[]\n",
    "X_validation=[]\n",
    "X_test=[]\n",
    "Y_train=[]\n",
    "Y_validation=[]\n",
    "Y_test=[]\n",
    "with open('Train1.npy', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "    Y_train = np.load(f)\n",
    "with open('Validation1.npy', 'rb') as f1:\n",
    "    X_validation = np.load(f1)\n",
    "    Y_validation = np.load(f1)\n",
    "with open('Test1.npy', 'rb') as f2:\n",
    "    X_test = np.load(f2)\n",
    "    Y_test = np.load(f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import DNN model from file\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('DNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RF and KNC models from file\n",
    "import joblib\n",
    "model1 = joblib.load('RF.sav')\n",
    "model2 = joblib.load('KNC.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "i 1\n",
      "i 2\n",
      "i 3\n",
      "i 4\n",
      "i 5\n",
      "i 6\n",
      "i 7\n",
      "i 8\n",
      "i 9\n",
      "i 10\n",
      "i 11\n",
      "i 12\n",
      "i 13\n",
      "i 14\n",
      "i 15\n",
      "i 16\n",
      "i 17\n",
      "i 18\n",
      "i 19\n",
      "i 20\n",
      "i 21\n",
      "i 22\n",
      "i 23\n",
      "i 24\n",
      "i 25\n",
      "i 26\n",
      "i 27\n",
      "i 28\n",
      "i 29\n",
      "i 30\n",
      "i 31\n",
      "i 32\n",
      "i 33\n",
      "i 34\n",
      "i 35\n",
      "i 36\n",
      "i 37\n",
      "i 38\n",
      "i 39\n",
      "i 40\n",
      "i 41\n",
      "i 42\n",
      "i 43\n",
      "i 44\n",
      "i 45\n",
      "i 46\n",
      "i 47\n",
      "i 48\n",
      "i 49\n"
     ]
    }
   ],
   "source": [
    "# Testing with 50 random samples from test dataset\n",
    "from scipy import stats\n",
    "fl = open(\"Testing.txt\", \"w\")\n",
    "fl.write(\"Number,\\tDNNbrP,\\tRFbrP,\\tKNCbrP,\\tTTS1,\\tTTP1,\\tTTS2,\\tTTP2,\\tTTS3,\\tTTP3\\n\")\n",
    "for m in range(50):\n",
    "    ListOfSamples=[]\n",
    "    ListOfIndexes=[]\n",
    "    for j in range(1000):\n",
    "        ind=np.random.randint(0,1699)\n",
    "        ListOfSamples.append(X_test[ind])\n",
    "        ListOfIndexes.append(Y_test[ind])\n",
    "    ListOfSamples=np.array(ListOfSamples)\n",
    "    ModPred=np.argmax(model.predict(ListOfSamples),axis=1)\n",
    "    ModPred=np.array(ModPred)\n",
    "    ModBin=[]\n",
    "    MBP=0\n",
    "    for i in range (len(ListOfIndexes)):\n",
    "        if (ListOfIndexes[i]==ModPred[i]):\n",
    "            ModBin.append(0)\n",
    "            MBP+=1\n",
    "        else:\n",
    "            ModBin.append(1)\n",
    "    ModPred1=model1.predict(ListOfSamples)\n",
    "    ModBin1=[]\n",
    "    MBP1=0\n",
    "    for i in range (len(ListOfIndexes)):\n",
    "        if (ListOfIndexes[i]==ModPred1[i]):\n",
    "            ModBin1.append(0)\n",
    "            MBP1+=1\n",
    "        else:\n",
    "            ModBin1.append(1)\n",
    "    ModPred2=model2.predict(ListOfSamples)\n",
    "    ModBin2=[]\n",
    "    MBP2=0\n",
    "    for i in range (len(ListOfIndexes)):\n",
    "        if (ListOfIndexes[i]==ModPred2[i]):\n",
    "            ModBin2.append(0)\n",
    "            MBP2+=1\n",
    "        else:\n",
    "            ModBin2.append(1)\n",
    "    T1,tp1=stats.ttest_rel(ModBin2,ModBin)\n",
    "    T2,tp2=stats.ttest_rel(ModBin2,ModBin1)\n",
    "    T3,tp3=stats.ttest_rel(ModBin1,ModBin)\n",
    "    fl.write(str(m)+',\\t'+str(MBP)+',\\t'+str(MBP1)+',\\t'+str(MBP2)+',\\t'+str(T1)+',\\t'+str(tp1)+',\\t'+str(T2)+',\\t'+str(tp2)+',\\t'+str(T3)\n",
    "        +',\\t'+str(tp3)+'\\n')\n",
    "    print(\"i\",m)\n",
    "fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 57   0   9   8  62  11   1   0  15   7]\n",
      " [  4 121   0  11  15   2   5   1   4   7]\n",
      " [ 21   0  10   6 111  20   0   0   2   0]\n",
      " [  1   0   0 145  13   5   0   0   6   0]\n",
      " [  3   0   0   4 160   2   0   0   0   1]\n",
      " [  9   0   0  18  81  53   0   1   5   3]\n",
      " [ 16   0  19   9  56   3  18   2   1  46]\n",
      " [ 11   0  23   5  85   5   0  23   1  17]\n",
      " [  0   0   0  76   0  19   0   0  75   0]\n",
      " [  2   0   0  51  74   1   6   0  10  26]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix create and test\n",
    "from sklearn.metrics import confusion_matrix\n",
    "yp=model.predict(X_test)\n",
    "Pt1=np.argmax(yp,axis=1)\n",
    "cm1=confusion_matrix(Y_test,Pt1)\n",
    "Pt2=model1.predict(X_test)\n",
    "cm2=confusion_matrix(Y_test,Pt2)\n",
    "Pt3=model2.predict(X_test)\n",
    "cm3=confusion_matrix(Y_test,Pt3)\n",
    "print(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
